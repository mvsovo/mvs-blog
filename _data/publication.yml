publication:
  - year: '2023'
    pubs:
      - title: Evaluating the Impact of Human Explanation Strategies on Human-AI Visual Decision-Making
        image: satellite-explainability-cscw.jpg
        authors:
          - Katelyn C. Morrison
          - Donghoon Shin
          - Kenneth Holstein
          - Adam Perer
        id: cscw2023_satellite-explainability_paper
        venue: CSCW 2023
        venue_full: ''
        abstract: Artificial intelligence (AI) is increasingly being deployed in high-stakes domains, such as disaster relief and radiology, to aid practitioners during the decision-making process for interpreting images. Explainable AI techniques have been developed and deployed to provide users insights into why the AI made a certain prediction. However, recent research suggests that these techniques may confuse or mislead users. We conducted a series of two studies to uncover strategies human use to explain decisions and then understand how those explanation strategies impact visual decision-making. In our first study, we elicit explanations from humans when assessing and localizing damaged buildings after natural disasters from satellite imagery and identify four core explanation strategies that humans employed. We then follow-up by studying the impact of these explanation strategies by framing explanations from Study 1 as if they were generated by AI and showing them to a different set of decision-makers performing the same task. We provide initial insights on how causal explanation strategies improve humans’ accuracy and calibrate humans’ reliance on AI when the AI is incorrect. However, we also find that causal explanation strategies may lead to incorrect rationalizations when the AI presents a correct assessment with incorrect localization. We explore the implications of our findings for the design of human-centered explainable AI and address directions for future work.
        note: accepted with minor revision
        category: 
          - "AI / NLP"
          - "CSCW"
        featured: true
  - year: '2022'
    pubs:
      - title: Exploring the Effects of AI-assisted Emotional Support Processes in Online Mental Health Community
        image: omhc.jpg
        authors:
          - Donghoon Shin
          - Subeen Park
          - Esther Hehsun Kim
          - Soomin Kim
          - Jinwook Seo
          - Hwajung Hong
        id: chi2022_omhc_poster
        video: JVqjovjOcwo
        poster: chi2022_omhc_poster_conference.pdf
        slide: chi2022_omhc_slide.pdf
        venue: CHI 2022 Extended Abstracts
        venue_full: Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems
        abstract: Social support in online mental health communities (OMHCs) is an effective and accessible way of managing mental wellbeing. In this process, sharing emotional supports is considered crucial to the thriving social supports in OMHCs, yet often difficult for both seekers and providers. To support empathetic interactions, we design an AI-infused workflow that allows users to write emotional supporting messages to other users' posts based on the elicitation of the seeker's emotion and contextual keywords from writing. Based on a preliminary user study (N = 10), we identified that the system helped seekers to clarify emotion and describe text concretely while writing a post. Providers could also learn how to react empathetically to the post. Based on these results, we suggest design implications for our proposed system.
        bibtex: |-
          @inproceedings{omhcs,
                    title = {Exploring the Effects of AI-assisted Emotional Support Processes in Online Mental Health Community},
                    author = {Shin, Donghoon and Park, Subeen and Kim, Esther Hehsun and Kim, Soomin and Seo, Jinwook and Hong, Hwajung},
                    year = 2022,
                    booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
                    location = {New Orleans, LA, USA},
                    publisher = {ACM},
                    address = {New York, NY, USA},
                    series = {CHI EA '22},
                    doi = {10.1145/3491101.3519854},
                    isbn = {978-1-4503-9156-6/22/04},
                    url = {http://doi.acm.org/10.1145/3491101.3519854},
                    keywords = {online mental health community, AI-infused system, emotional support, peer support}
                  }
        note: Late-breaking work
        category: 
          - "AI / NLP"
          - "Healthcare"
          - "CSCW"
        featured: true
      - title: Leveraging AI to Assist Emotional Supports in Online Mental Health Community
        image: omhc-flow.jpg
        authors:
          - Donghoon Shin
          - Subeen Park
          - Esther Hehsun Kim
          - Soomin Kim
          - Jinwook Seo
          - Hwajung Hong
        id: chi2022_omhc_workshop
        venue: CHI 2022 Workshop
        venue_full: Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems
        abstract: Although sharing emotional supports in online mental health communities (OMHCs) is an effective and accessible way of managing mental wellbeing, it is often difficult for both seekers and providers. To support empathetic interactions, we design an AI-infused workflow that allows users to write emotional supporting messages to other users' posts based on the elicitation of the seeker's emotion and contextual keywords from writing. Based on a preliminary user study (N = 10), we identified that the system helped seekers to clarify emotion and describe text concretely while writing a post. Providers could also learn how to react empathetically to the post. Based on these results, we suggest design implications for our proposed system.
        bibtex: |-
          @inproceedings{omhcs_workshop,
                    title = {Leveraging AI to Assist Emotional Supports in Online Mental Health Community},
                    author = {Shin, Donghoon and Park, Subeen and Kim, Esther Hehsun and Kim, Soomin and Seo, Jinwook and Hong, Hwajung},
                    year = 2022,
                    booktitle = {CHI 2022 Workshop on the Future of Emotion in HCI},
                    location = {New Orleans, LA, USA},
                    keywords = {online mental health community, AI-infused system, emotional support, peer support}
                  }
        note: Future of Emotion in HCI
        category: 
          - "AI / NLP"
          - "Healthcare"
          - "CSCW"
      - title: "AmslerTouch: Self-testing Amsler Grid Application for Supporting a Quantitative Report of AMD Symptoms"
        image: amslertouch.jpg
        id: hcik2022_amslertouch_paper
        authors:
          - Donghoon Shin
        slide: hcik2022_amslertouch_slide.pdf
        video: YK8v5d85ZMU
        venue: HCIK 2022
        venue_full: Proceedings of HCI Korea 2022
        category:
          - "Healthcare"
        bibtex: |-
          @inproceedings{amslertouch,
                    title = {AmslerTouch: Self-testing Amsler Grid Application for Supporting a Quantitative Report of Age-related Macular Degeneration Symptoms},
                    author = {Shin, Donghoon},
                    year = 2022,
                    booktitle = {Proceedings of the 2022 HCI Korea},
                    publisher = {HCI Korea},
                    series = {HCI Korea '22},
                    keywords = {Healthcare, Medical informatics}
                  }
        abstract: Age-related macular degeneration (AMD) is a progressive chronic disease that is led by damage in the macula. Due to its irreversible characteristics and disastrous effects on the patients, a precise diagnosis of the symptoms is extremely important. Yet, paperbased Amsler Grid, which is known as the most prevalent testing method, is highly limited in that it requires the indirect report of patients and quantitative reporting is difficult. To address this, I propose AmslerTouch, a touch-based Amslertesting web app that supports patients to self-report AMD symptoms. Based on the heuristic evaluation for identifying enhancements, I also discuss possible enhancements of my proposed system.
  - year: '2021'
    pubs:
      - title: Characterizing Human Explanation Strategies to Inform the Design of Explainable AI for Building Damage Assessment
        image: satellite-explainability-neurips.jpg
        id: neurips2021_satellite-explainability_workshop
        authors:
          - Donghoon Shin
          - Sachin Grover
          - Kenneth Holstein
          - Adam Perer
        venue: NeurIPS 2021 Workshop
        abstract: Explainable AI (XAI) is a promising means of supporting human-AI collaborations for high-stakes visual detection tasks, such as damage detection tasks from satellite imageries, as fully-automated approaches are unlikely to be perfectly safe and reliable. However, most existing XAI techniques are not informed by the understandings of task-specific needs of humans for explanations. Thus, we took a first step toward understanding what forms of XAI humans require in damage detection tasks. We conducted an online crowdsourced study to understand how people explain their own assessments, when evaluating the severity of building damage based on satellite imagery. Through the study with 60 crowdworkers, we surfaced six major strategies that humans utilize to explain their visual damage assessments. We present implications of our findings for the design of XAI methods for such visual detection contexts, and discuss opportunities for future research.
        note: AI for HADR
        venue_full: NeurIPS 2021 Workshop on AI for Humanitarian Assistance and Disaster Response
        poster: neurips2021_satellite-explainability_poster.pdf
        category:
          - "AI / NLP"
        bibtex: |-
          @inproceedings{satellite,
                    title = {Characterizing Human Explanation Strategies to Inform the Design of Explainable AI for Building Damage Assessment},
                    author = {Shin, Donghoon and Grover, Sachin and Holstein, Kenneth and Perer, Adam},
                    year = 2021,
                    booktitle = {NeurIPS 2021 Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response},
                    location = {Sydney, Australia},
                    keywords = {explainable AI, satellite imagery, damage detection, disaster response}
                  }
      - title: "Trkic G00gle: Why and How Users Game Translation Algorithms"
        image: trkic-g00gle.jpg
        id: cscw2021_trkic-g00gle_paper
        video: VVAQqC5tedQ
        authors:
          - Soomin Kim
          - Changhoon Oh
          - Won Ik Cho
          - Donghoon Shin
          - Bongwon Suh
          - Joonhwan Lee
        venue: CSCW 2021
        venue_full: 'Proceedings of the ACM on Human-Computer Interaction, 5(CSCW2)'
        abstract: Individuals interact with algorithms in various ways. Users even game and circumvent algorithms so as to achieve favorable outcomes. This study aims to come to an understanding of how various stakeholders interact with each other in tricking algorithms, with a focus towards online review communities. We employed a mixed-method approach in order to explore how and why users write machine non-translatable reviews as well as how those encrypted messages are perceived by those receiving them. We found that users are able to find tactics to trick the algorithms in order to avoid censoring, to mitigate interpersonal burden, to protect privacy, and to provide authentic information for enabling the formation of informative review communities. They apply several linguistic and social strategies in this regard. Furthermore, users perceive encrypted messages as both more trustworthy and authentic. Based on these findings, we discuss implications for online review community and content moderation algorithms.
        category:
          - "AI / NLP"
          - "CSCW"
        bibtex: |-
          @article{trkicg00gle,
                    title = {Trkic G00gle: Why and How Users Game Translation Algorithms},
                    author = {Kim, Soomin and Oh, Changhoon and Cho, Won Ik and Shin, Donghoon and Suh, Bongwon and Lee, Joonhwan},
                    year = 2021,
                    journal = {Proceedings of the ACM on Human-Computer Interaction},
                    publisher = {ACM},
                    address = {New York, NY, USA},
                    volume = 5,
                    number = {CSCW2},
                    pages = {1--24},
                    doi = {10.1145/3476085},
                    url = {http://doi.acm.org/10.1145/3476085},
                    keywords = {Human-AI Interaction, algorithmic experience, gaming, translation algorithm, online review, recommendation algorithm, peer-to-peer platform}
                  }
        featured: true
      - title: "BlahBlahBot: Facilitating Conversation between Strangers using a Chatbot with ML-infused Personalized Topic Suggestion"
        image: blahblahbot.jpg
        id: chi2021_blahblahbot_poster
        authors:
          - Donghoon Shin
          - Sangwon Yoon
          - Soomin Kim
          - Joonhwan Lee
        venue: CHI 2021 Extended Abstracts
        venue_full: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
        note: Late-breaking work
        abstract: It is a prevalent behavior of having a chat with strangers in online settings where people can easily gather. Yet, people often fnd it difcult to initiate and maintain conversation due to the lack of information about strangers. Hence, we aimed to facilitate conversation between the strangers with the use of machine learning (ML) algorithms and present BlahBlahBot, an ML-infused chatbot that moderates conversation between strangers with personalized topics. Based on social media posts, BlahBlahBot supports the conversation by suggesting topics that are likely to be of mutual interest between users. A user study with three groups (control, random topic chatbot, and BlahBlahBot; N=18) found the feasibility of BlahBlahBot in increasing both conversation quality and closeness to the partner, along with the factors that led to such increases from the user interview. Overall, our preliminary results imply that an ML-infused conversational agent can be efective for augmenting a dyadic conversation.
        poster: chi2021_blahblahbot_poster_conference.pdf
        video: 0blBM7xkELw
        category: 
          - "AI / NLP"
          - "Chatbot"
          - "CSCW"
        bibtex: |-
          @inproceedings{blahblahbot,
                    title = {BlahBlahBot: Facilitating Conversation between Strangers using a Chatbot with ML-infused Personalized Topic Suggestion based on Social Media Posts},
                    author = {Shin, Donghoon and Yoon, Sangwon and Kim, Soomin and Lee, Joonhwan},
                    year = 2021,
                    booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
                    location = {Yokohama, Japan},
                    publisher = {ACM},
                    address = {New York, NY, USA},
                    series = {CHI EA '21},
                    doi = {10.1145/3411763.3451771},
                    isbn = {978-1-4503-8095-9/21/05},
                    url = {http://doi.acm.org/10.1145/3411763.3451771},
                    keywords = {chatbot, topic suggestion, computer mediated communication, chat moderation}
                  }
        featured: true
      - title: "Design Guidelines of Computer-based Intervention for Computer Vision Syndrome: Focus Group Study and In-the-wild Deployment"
        image: liquideye.jpg
        id: jmir_liquideye_paper
        authors:
          - Youjin Hwang
          - Donghoon Shin
          - Jinsu Eun
          - Bongwon Suh
          - Joonhwan Lee
        venue: 'Journal of Medical Internet Research 23(3), 2021'
        venue_full: 'Journal of Medical Internet Research, 23(3), e22099'
        category: 
          - "Healthcare"
        abstract: >-
          Background:

          Prolonged time of computer use increases the prevalence of ocular
          problems, including eye strain, tired eyes, irritation, redness, blurred
          vision, and double vision, which are collectively referred to as
          computer vision syndrome (CVS). Approximately 70% of computer users have
          vision-related problems. For these reasons, properly designed
          interventions for users with CVS are required. To design an effective
          screen intervention for preventing or improving CVS, we must understand
          the effective interfaces of computer-based interventions.


          Objective:

          In this study, we aimed to explore the interface elements of
          computer-based interventions for CVS to set design guidelines based on
          the pros and cons of each interface element.


          Methods:

          We conducted an iterative user study to achieve our research objective.
          First, we conducted a workshop to evaluate the overall interface
          elements that were included in previous systems for CVS (n=7). Through
          the workshop, participants evaluated existing interface elements. Based
          on the evaluation results, we eliminated the elements that negatively
          affect intervention outcomes. Second, we designed our prototype system
          LiquidEye that includes multiple interface options (n=11). Interface
          options included interface elements that were positively evaluated in
          the workshop study. Lastly, we deployed LiquidEye in the real world to
          see how the included elements affected the intervention outcomes.
          Participants used LiquidEye for 14 days, and during this period, we
          collected participants’ daily logs (n=680). Additionally, we conducted
          prestudy and poststudy surveys, and poststudy interviews to explore how
          each interface element affects participation in the system.


          Results:

          User data logs collected from the 14 days of deployment were analyzed
          with multiple regression analysis to explore the interface elements
          affecting user participation in the intervention (LiquidEye).
          Statistically significant elements were the instruction page of the eye
          resting strategy (P=.01), goal setting of the resting period (P=.009),
          compliment feedback after completing resting (P<.001), a mid-size popup
          window (P=.02), and CVS symptom-like effects (P=.004).


          Conclusions:

          Based on the study results, we suggested design implications to consider
          when designing computer-based interventions for CVS. The sophisticated
          design of the customization interface can make it possible for users to
          use the system more interactively, which can result in higher engagement
          in managing eye conditions. There are important technical challenges
          that still need to be addressed, but given the fact that this study was
          able to clarify the various factors related to computer-based
          interventions, the findings are expected to contribute greatly to the
          research of various computer-based intervention designs in the future.
        bibtex: |-
          @article{liquideye,
                    title = {Design Guidelines of Computer-based Intervention for Computer Vision Syndrome: Focus Group Study and In-the-wild Deployment},
                    author = {Hwang, Youjin and Shin, Donghoon and Eun, Jinsu and Suh, Bongwon and Lee, Joonhwan},
                    year = 2021,
                    month = {Feb},
                    day = 25,
                    journal = {J Med Internet Res},
                    doi = {10.2196/22099},
                    url = {https://doi.org/10.2196/22099}
                  }
  - year: '2020'
    pubs:
      - title: "TalkingBoogie: Collaborative Mobile AAC System for Non-verbal Children with Developmental Disabilities and Their Caregivers"
        image: talkingboogie.jpg
        id: chi2020_talkingboogie_paper
        authors:
          - Donghoon Shin
          - Jaeyoon Song
          - Seokwoo Song
          - Jisoo Park
          - Joonhwan Lee
          - Soojin Jun
        venue: CHI 2020
        venue_full: "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems"
        abstract: "Augmentative and alternative communication (AAC) technologies are widely used to help non-verbal children enable communication. For AAC-aided communication to be successful, caregivers should support children with consistent intervention strategies in various settings. As such, caregivers need to continuously observe and discuss children's AAC usage to create a shared understanding of these strategies. However, caregivers often find it challenging to effectively collaborate with one another due to a lack of family involvement and the unstructured process of collaboration. To address these issues, we present TalkingBoogie, which consists of two mobile apps: TalkingBoogie-AAC for caregiver-child communication, and TalkingBoogie-coach supporting caregiver collaboration. Working together, these applications provide contextualized layouts for symbol arrangement, scaffold the process of sharing and discussing observations, and induce caregivers' balanced participation. A two-week deployment study with four groups (N=11) found that TalkingBoogie helped increase mutual understanding of strategies and encourage balanced participation between caregivers with reduced cognitive loads."
        award: Honorable Mention Award
        slide: chi2020_talkingboogie_slide.pdf
        category: 
          - "Healthcare"
          - "CSCW"
        bibtex: |-
          @inproceedings{talkingboogie,
                    title = {TalkingBoogie: Collaborative Mobile AAC System for Non-verbal Children with Developmental Disabilities and Their Caregivers},
                    author = {Shin, Donghoon and Song, Jaeyoon and Song, Seokwoo and Park, Jisoo and Lee, Joonhwan and Jun, Soojin},
                    year = 2020,
                    booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
                    location = {Honolulu, HI, USA},
                    publisher = {ACM},
                    address = {New York, NY, USA},
                    series = {CHI '20},
                    doi = {10.1145/3313831.3376154},
                    isbn = {978-1-4503-6708-0/20/04},
                    url = {http://doi.acm.org/10.1145/3313831.3376154},
                    keywords = {AAC, developmental disability, assistive technology, caregiver collaboration, accessibility}
                  }
        featured: true
      - title: "Applying the Persona of User’s Family Member and the Doctor to the Conversational Agents for Healthcare"
        image: personabot.jpg
        id: chi2020_personabot_workshop
        authors:
          - Youjin Hwang
          - Donghoon Shin
          - Sion Baek
          - Bongwon Suh
          - Joonhwan Lee
        venue: CHI 2020 Workshop
        venue_full: CHI 2020 Workshop on Conversational Agents for Health and Wellbeing
        abstract: Conversational agents have been showing lots of opportunities in healthcare by taking over a lot of tasks that used to be done by a human. One of the major functions of conversational healthcare agent is intervening users’ daily behaviors. In this case, forming an intimate and trustful relationship with users is one of the major issues. Factors affecting human-agent relationship should be deeply explored to improve long-term acceptance of healthcare agent. Even though a bunch of ideas and researches have been suggested to increase the acceptance of conversational agents in healthcare, challenges still remain. From the preliminary work we conducted, we suggest an idea of applying the personas of users’ family members and the doctor who are in the relationship with users in the real world as a solution for forming the rigid relationship between humans and the chatbot.
        note: CAs for Health and Wellbeing
        category: 
          - "AI / NLP"
          - "Healthcare"
          - "Chatbot"
          - "CSCW"
        bibtex: |-
          @inproceedings{chatbotpersona,
                    title = {Applying the Persona of User’s Family Member and the Doctor to the Conversational Agents for Healthcare},
                    author = {Hwang, Youjin and Shin, Donghoon and Baek, Sion and Suh, Bongwon and Lee, Joonhwan},
                    year = 2020,
                    booktitle = {CHI 2020 Workshop on Conversational Agents for Health and Wellbeing},
                    location = {Honolulu, HI, USA},
                    keywords = {chatbot, persona, healthcare}
                  }
      - title: Linguistic Features to Consider When Applying Persona of the Real Persona to the Text-based Agent
        image: prp.jpg
        id: mobilehci2020_prp_poster
        authors:
          - Youjin Hwang
          - Seokwoo Song
          - Donghoon Shin
          - Joonhwan Lee
        venue: MobileHCI 2020 Extended Abstracts
        venue_full: 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services
        abstract: As artificial intelligence (AI) technologies advance, the possibility of developing virtual agents capable of mimicking human beings is increasing. Furthermore, AI techniques applicable to mimicking certain features of a specific person (e.g., facial expression, voice, motion) are becoming more sophisticated. Although the HCI community has explored how to design or develop AI agents mimicking a real person, limited studies on mimicking someone’s text-based behavior shown in the instant messaging exist. This study investigates the features that make users perceive text-based agents as people they know in reality. On top of the previous efforts of designing human-like virtual agents, our work suggests design guidelines for applying the persona of the real person (PRP) to text-based agents.
        note: Late-breaking result
        category: 
          - "AI / NLP"
          - "Healthcare"
          - "Chatbot"
          - "CSCW"
        bibtex: |-
          @inproceedings{linguisticfeatures,
                    title = {Linguistic Features to Consider When Applying Persona of the Real Persona to the Text-based Agent},
                    author = {Hwang, Youjin and Song, Seokwoo and Shin, Donghoon and Lee, Joonhwan},
                    year = 2020,
                    booktitle = {22th International Conference on Human-Computer Interaction with Mobile Devices and Services},
                    location = {Oldenburg, Germany},
                    publisher = {ACM},
                    address = {New York, NY, USA},
                    series = {MobileHCI '20},
                    doi = {10.1145/3406324.3410723},
                    isbn = {978-1-4503-8052-2/20/10},
                    url = {http://doi.acm.org/10.1145/3406324.3410723},
                    keywords = {chatbot, chat analysis, personality, authorship attribution}
                  }
